@article{fontaine2021differentiable,
  title={Differentiable Quality Diversity},
  author={Matthew C. Fontaine and Stefanos Nikolaidis},
  year={2021},
  month={June},
  url={https://arxiv.org/abs/2106.03894},
  journal={arXiv},
  volume={abs/2012.04283},
  archivePrefix={arXiv},
  eprint={2012.04283},
  abstract={Quality diversity (QD) is a growing branch of stochastic optimization research that studies the problem of generating an archive of solutions that maximize a given objective function but are also diverse with respect to a set of specified measure functions. However, even when these functions are differentiable, QD algorithms treat them as "black boxes", ignoring gradient information. We present the differentiable quality diversity (DQD) problem, a special case of QD, where both the objective and measure functions are first order differentiable. We then present MAP-Elites via Gradient Arborescence (MEGA), a DQD algorithm that leverages gradient information to efficiently explore the joint range of the objective and measure functions. Results in two QD benchmark domains and in searching the latent space of a StyleGAN show that MEGA significantly outperforms state-of-the-art QD algorithms, highlighting DQD's promise for efficient quality diversity optimization when gradient information is available.},
}
